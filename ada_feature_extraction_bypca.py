# -*- coding: utf-8 -*-
"""ADA - Feature extraction_byPCA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hUC12Yyh0MNTaRVsl5QG83LC10Gy7jXZ
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

"""Principal Component Analysis"""

df = pd.read_csv('niewydolnoscSerca.csv', sep=',')
df.head()

df.shape

df.isnull().sum()

"""Brak niewypełnionych wartości """

df.info()

#Age jest float64 a powinna być int

df['age'] = df['age'].astype(int)

df.info()

#Dtype poprawne (teraz)

"""Analiza danych """

import plotly.express as px
import matplotlib.pyplot as plt

px.histogram(x = 'age', y = 'DEATH_EVENT', data_frame = df, color = 'sex', 
             labels = {'age' : 'Age Group', 'DEATH_EVENT' : 'Number of Deaths'}, barmode='group')

px.histogram(data_frame = df, x = 'creatinine_phosphokinase', y = 'DEATH_EVENT', color = 'sex', barmode = 'group', range_x = (0, 2500), 
            labels = {'creatinine_phosphokinase' : 'Amount of Creatinine Phosphokinase (Lower is Better)', 'Death_Event' : 'Number of Deaths'})

"""Skalowanie danych """

from sklearn.preprocessing import StandardScaler

# dystrybucja zbioru danych na dwa komponenty X i Y

X = df.drop(['DEATH_EVENT'], axis = 1)
y = df['DEATH_EVENT']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

X_train.shape

X_test.shape

#Dzielenie zbioru danych na zbiór treningowy i zbiór testowy

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

#Skalowanie funkcji

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()

X_train = sc.fit_transform(X_train)

X_test = sc.transform(X_test)

# Stosowanie funkcji PCA na treningu

from sklearn.decomposition import PCA

pca = PCA(n_components = 2)

X_train = pca.fit_transform(X_train)

X_test = pca.transform(X_test)

explained_variance = pca.explained_variance_ratio_

#Dopasowanie regresji logistycznej do zestawu treningowego

from sklearn.linear_model import LogisticRegression

classifier = LogisticRegression(random_state = 0)
classifier.fit(X_train, y_train)

#Przewidywanie wyniku zestawu testowego

y_pred = classifier.predict(X_test)

#Tworzenie macierzy pomyłek

from sklearn.metrics import confusion_matrix
 
cm = confusion_matrix(y_test, y_pred)

#Przewidywanie wyników setów trenujących

from matplotlib.colors import ListedColormap
 
X_set, y_set = X_train, y_train
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1,
                     stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1,
                     stop = X_set[:, 1].max() + 1, step = 0.01))

plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(),
             X2.ravel()]).T).reshape(X1.shape), alpha = 0.75,
             cmap = ListedColormap(('yellow', 'white', 'aquamarine')))
 
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
 
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)
 
plt.title('Logistic Regression (Training set)')
plt.xlabel('PC1') # for Xlabel
plt.ylabel('PC2') # for Ylabel
plt.legend() # to show legend
 
plt.show()

#wizualizacja

from matplotlib.colors import ListedColormap
 
X_set, y_set = X_test, y_test
 
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1,
                     stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1,
                     stop = X_set[:, 1].max() + 1, step = 0.01))
 
plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(),
             X2.ravel()]).T).reshape(X1.shape), alpha = 0.75,
             cmap = ListedColormap(('yellow', 'white', 'aquamarine')))
 
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
 
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)
 
# title for scatter plot
plt.title('Logistic Regression (Test set)')
plt.xlabel('PC1') # for Xlabel
plt.ylabel('PC2') # for Ylabel
plt.legend()
 
# show scatter plot
plt.show()

"""Linear Discriminant Analysis"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

dataset  = pd.read_csv('Oscar.csv', sep=';', on_bad_lines='skip')
dataset .head()

dataset .shape

dataset .isnull().sum()

dataset.drop('IMDB Votes', axis=1, inplace=True)
dataset.drop('Film', axis=1, inplace=True)

dataset .isnull().sum()

"""Brak niewypełnionych wartości """

dataset.info()

#zmiana tekstowych wartości na binarne w Award

Award = dataset['Award'].replace(['Nominee','Winner'],[0,1],inplace=True)

dataset

#podział zbioru danych na cechy

x_data = dataset[['Movie Time', 'IMDB Rating']]
y_data = dataset['Award']

x_data

y_data

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x_data, y_data ,test_size = 0.2, shuffle=False)

from sklearn import linear_model
linear_regression_model = linear_model.LinearRegression()
linear_regression_model.fit(x_train, y_train)

y_pred = linear_regression_model.predict(x_test)

y_pred

#standaryzacja zbioru danych

import numpy as np
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

model = LinearDiscriminantAnalysis()

model.fit(x_data, y_data)

print(model.predict)

from sklearn.datasets import make_classification

data_projected = model.fit_transform(x_data, y_data)

print(data_projected.shape)

dataset

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
lda = LinearDiscriminantAnalysis()
X_lda = lda.fit_transform(X, y)

lda.explained_variance_ratio_

plt.xlabel('LD1')
plt.ylabel('LD2')
plt.scatter(
    X_lda[:,0],
    X_lda[:,1],
    c=y,
    cmap='rainbow',
    alpha=0.7,
    edgecolors='b'
)