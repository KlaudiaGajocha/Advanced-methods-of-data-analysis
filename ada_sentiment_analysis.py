# -*- coding: utf-8 -*-
"""ADA - Sentiment analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ugONtFyS3X0Wxi13t5QrDBc3GfG-l3X2
"""

import pandas as pd
reviews_df = pd.read_csv('HotelReviews.csv', sep=";")
# Scalenie wartości w kolumnach Positive_Reviewi Negative_Review
reviews_df["review"] = reviews_df["Negative_Review"] + reviews_df["Positive_Review"]
# Zakodowanie ogólnej oceny hotelu w formie binarnej
reviews_df["is_bad_review"] = reviews_df["Reviewer_Score"].apply(lambda x: 1 if x < 5 else 0)


reviews_df = reviews_df[["review", "is_bad_review"]]
reviews_df.head()

reviews_df = reviews_df.sample(frac = 0.1, replace = False, random_state=42)

#Usunięcie z tekstów recenzji wyrażeń „No positive”, „No negative”
reviews_df["review"] = reviews_df["review"].apply(lambda x: x.replace("No Negative", "").replace("No Positive", ""))

# zwraca wartości obiektu wordnet odpowiadającą tagowi POS
from nltk.corpus import wordnet

def get_wordnet_pos(pos_tag):
    if pos_tag.startswith('J'):
        return wordnet.ADJ
    elif pos_tag.startswith('V'):
        return wordnet.VERB
    elif pos_tag.startswith('N'):
        return wordnet.NOUN
    elif pos_tag.startswith('R'):
        return wordnet.ADV
    else:
        return wordnet.NOUN

import string
from nltk import pos_tag
from nltk.corpus import stopwords
from nltk.tokenize import WhitespaceTokenizer
from nltk.stem import WordNetLemmatizer

def clean_text(text):
    # Zamianę wszystkich wielkich liter w tekście recenzji na małe.
    text = text.lower()
    # tokenizacja teksty i usuwanie znaków interpunkcyjnych
    text = [word.strip(string.punctuation) for word in text.split(" ")]
    # usuwanie słowów zawierających liczby
    text = [word for word in text if not any(c.isdigit() for c in word)]
    # usunięcie stop words
    stop = stopwords.words('english')
    text = [x for x in text if x not in stop]
    # usunięcie pustych tokenów
    text = [t for t in text if len(t) > 0]
    pos_tags = pos_tag(text)
    # Lematyzację słów
    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]
    # usunięcie słów z tylko jedną literą 
    text = [t for t in text if len(t) > 1]
    
    text = " ".join(text)
    return(text)

# czyszczenie danych tekstowych
import nltk
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')
reviews_df["review_clean"] = reviews_df["review"].apply(lambda x: clean_text(x))

# dodanie kolumny analizy sentymentu
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import nltk
nltk.download('vader_lexicon')

sid = SentimentIntensityAnalyzer()
reviews_df["sentiments"] = reviews_df["review"].apply(lambda x: sid.polarity_scores(x))
reviews_df = pd.concat([reviews_df.drop(['sentiments'], axis=1), reviews_df['sentiments'].apply(pd.Series)], axis=1)

# Analizę sentymentówi wyświetlenie 10 najlepszych i najgorszych recenzji (z tych, które mają więcej niż 5 słów).

#najlepsze
reviews_df[reviews_df["nb_words"] >= 5].sort_values("pos", ascending = False)[["review", "pos"]].head(10)

#najgorsze
reviews_df[reviews_df["nb_words"] >= 5].sort_values("neg", ascending = False)[["review", "neg"]].head(10)

#Klasyfikacja recenzji z wykorzystaniem dowolnego klasyfikatora

# selekcja cech 
label = "is_bad_review"
ignore_cols = [label, "review", "review_clean"]
features = [c for c in reviews_df.columns if c not in ignore_cols]

# podział danych na trenujące i testujące
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(reviews_df[features], reviews_df[label], test_size = 0.20, random_state = 42)

# trenowanie  random forest classifier
rf = RandomForestClassifier(n_estimators = 100, random_state = 42)
rf.fit(X_train, y_train)

# Pokazanie znaczenia funkcji
feature_importances_df = pd.DataFrame({"feature": features, "importance": rf.feature_importances_}).sort_values("importance", ascending = False)
feature_importances_df.head(20)

# Krzywa ROC - obrazuje jak duży będzie odsetek błędnych klasyfikacji (pozytywnych i negatywnych) dla danego punktu odcięcia

from sklearn.metrics import roc_curve, auc, roc_auc_score
import matplotlib.pyplot as plt

y_pred = [x[1] for x in rf.predict_proba(X_test)]
fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label = 1)

roc_auc = auc(fpr, tpr)

plt.figure(1, figsize = (15, 10))
lw = 2
plt.plot(fpr, tpr, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()

# Krzywa precision-recall pokazuje zależność pomiędzy miarami precision i recall dla różnych wartości odcięcia klasyfikatora. 
#Pokazuje ona  ogólną zdolność klasyfikatora do rozpoznawania. 

from sklearn.metrics import average_precision_score, precision_recall_curve
from sklearn.utils.fixes import signature

average_precision = average_precision_score(y_test, y_pred)

precision, recall, _ = precision_recall_curve(y_test, y_pred)


step_kwargs = ({'step': 'post'}
               if 'step' in signature(plt.fill_between).parameters
               else {})

plt.figure(1, figsize = (15, 10))
plt.step(recall, precision, color='b', alpha=0.2,
         where='post')
plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))